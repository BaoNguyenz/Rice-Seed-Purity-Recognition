{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:07.982005Z",
     "iopub.status.busy": "2024-09-19T10:36:07.981713Z",
     "iopub.status.idle": "2024-09-19T10:36:21.936996Z",
     "shell.execute_reply": "2024-09-19T10:36:21.935768Z",
     "shell.execute_reply.started": "2024-09-19T10:36:07.981974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input, LayerNormalization, Dropout, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:21.939520Z",
     "iopub.status.busy": "2024-09-19T10:36:21.938863Z",
     "iopub.status.idle": "2024-09-19T10:36:53.754909Z",
     "shell.execute_reply": "2024-09-19T10:36:53.753976Z",
     "shell.execute_reply.started": "2024-09-19T10:36:21.939483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '/kaggle/input/huong-thom/Huongthom'\n",
    "\n",
    "garbage_types = os.listdir(dataset_path)\n",
    "\n",
    "all_dimensions_set = set()\n",
    "\n",
    "for garbage_type in garbage_types:\n",
    "    folder_path = os.path.join(dataset_path, garbage_type)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.endswith(('png', 'jpeg', 'jpg'))]\n",
    "\n",
    "        num_images = len(image_files)\n",
    "        print(f\"{garbage_type} folder contains {num_images} images.\")\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            with Image.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                channels = len(img.getbands())\n",
    "                all_dimensions_set.add((width, height, channels))\n",
    "\n",
    "if len(all_dimensions_set) == 1:\n",
    "    width, height, channels = all_dimensions_set.pop()\n",
    "    print(f\"\\nAll images in the dataset have the same dimensions: {width}x{height} with {channels} color channels.\")\n",
    "else:\n",
    "    print(\"\\nThe images in the dataset have different dimensions or color channels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:53.757659Z",
     "iopub.status.busy": "2024-09-19T10:36:53.756834Z",
     "iopub.status.idle": "2024-09-19T10:36:54.745358Z",
     "shell.execute_reply": "2024-09-19T10:36:54.744421Z",
     "shell.execute_reply.started": "2024-09-19T10:36:53.757607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for garbage_type in garbage_types:\n",
    "    folder_path = os.path.join(dataset_path, garbage_type)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.endswith(('png', 'jpeg', 'jpg'))]\n",
    "\n",
    "        image_files = image_files[:7]\n",
    "\n",
    "        fig, axs = plt.subplots(1, 7, figsize=(15, 2))\n",
    "\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            with Image.open(image_path) as img:\n",
    "                axs[i].imshow(img)\n",
    "                axs[i].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.suptitle(garbage_type, fontsize=20, y=1.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:54.748033Z",
     "iopub.status.busy": "2024-09-19T10:36:54.747678Z",
     "iopub.status.idle": "2024-09-19T10:36:54.752830Z",
     "shell.execute_reply": "2024-09-19T10:36:54.751721Z",
     "shell.execute_reply.started": "2024-09-19T10:36:54.747994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data = []\n",
    "\n",
    "# for garbage_type in garbage_types:\n",
    "#     for file in os.listdir(os.path.join(dataset_path, garbage_type)):\n",
    "#         data.append((os.path.join(dataset_path, garbage_type, file), garbage_type))\n",
    "\n",
    "# df = pd.DataFrame(data, columns=['filepath', 'label'])\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "# temp, val_df = train_test_split(df, test_size=0.3, stratify=df['label'])\n",
    "# train_df, test_df = train_test_split(temp, test_size=0.1, stratify=temp['label'])\n",
    "\n",
    "# print(f\"Number of images in the training set: {len(train_df)}\")\n",
    "# print(f\"Number of images in the test set: {len(test_df)}\")\n",
    "# print(f\"Number of images in the validation set: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:54.754747Z",
     "iopub.status.busy": "2024-09-19T10:36:54.754153Z",
     "iopub.status.idle": "2024-09-19T10:36:54.809852Z",
     "shell.execute_reply": "2024-09-19T10:36:54.808747Z",
     "shell.execute_reply.started": "2024-09-19T10:36:54.754703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for garbage_type in garbage_types:\n",
    "    for file in os.listdir(os.path.join(dataset_path, garbage_type)):\n",
    "        data.append((os.path.join(dataset_path, garbage_type, file), garbage_type))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['filepath', 'label'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "train_ratio = 0.55\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.30\n",
    "\n",
    "temp, val_df = train_test_split(df, test_size=val_ratio, stratify=df['label'])\n",
    "\n",
    "train_df, test_df = train_test_split(temp, test_size=test_ratio / (train_ratio + test_ratio), stratify=temp['label'])\n",
    " \n",
    "print(f\"Number of images in the training set: {len(train_df)}\")\n",
    "print(f\"Number of images in the test set: {len(test_df)}\")\n",
    "print(f\"Number of images in the validation set: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:54.811310Z",
     "iopub.status.busy": "2024-09-19T10:36:54.811009Z",
     "iopub.status.idle": "2024-09-19T10:36:57.143986Z",
     "shell.execute_reply": "2024-09-19T10:36:57.143187Z",
     "shell.execute_reply.started": "2024-09-19T10:36:54.811278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, InceptionV3, EfficientNetB0\n",
    "\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:57.145341Z",
     "iopub.status.busy": "2024-09-19T10:36:57.145046Z",
     "iopub.status.idle": "2024-09-19T10:36:57.218836Z",
     "shell.execute_reply": "2024-09-19T10:36:57.217875Z",
     "shell.execute_reply.started": "2024-09-19T10:36:57.145310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "# x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:57.220553Z",
     "iopub.status.busy": "2024-09-19T10:36:57.220230Z",
     "iopub.status.idle": "2024-09-19T10:36:57.233288Z",
     "shell.execute_reply": "2024-09-19T10:36:57.232452Z",
     "shell.execute_reply.started": "2024-09-19T10:36:57.220510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:57.235057Z",
     "iopub.status.busy": "2024-09-19T10:36:57.234654Z",
     "iopub.status.idle": "2024-09-19T10:36:57.240678Z",
     "shell.execute_reply": "2024-09-19T10:36:57.239792Z",
     "shell.execute_reply.started": "2024-09-19T10:36:57.235013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=30, verbose=1, mode='min'\n",
    ")\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(\n",
    "#     monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6, verbose=1, mode='min'\n",
    "# )\n",
    "\n",
    "csv_logger = CSVLogger('training_log.csv')\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:57.244302Z",
     "iopub.status.busy": "2024-09-19T10:36:57.244035Z",
     "iopub.status.idle": "2024-09-19T10:36:59.263171Z",
     "shell.execute_reply": "2024-09-19T10:36:59.262191Z",
     "shell.execute_reply.started": "2024-09-19T10:36:57.244272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    class_mode='binary'  \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:36:59.264747Z",
     "iopub.status.busy": "2024-09-19T10:36:59.264433Z",
     "iopub.status.idle": "2024-09-19T10:48:50.495813Z",
     "shell.execute_reply": "2024-09-19T10:48:50.494915Z",
     "shell.execute_reply.started": "2024-09-19T10:36:59.264714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=200,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n",
    "\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"Total training time: {training_time // 60} minutes and {training_time % 60} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:48:50.497249Z",
     "iopub.status.busy": "2024-09-19T10:48:50.496934Z",
     "iopub.status.idle": "2024-09-19T10:48:55.348214Z",
     "shell.execute_reply": "2024-09-19T10:48:55.347313Z",
     "shell.execute_reply.started": "2024-09-19T10:48:50.497217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_generator, steps=val_generator.samples // val_generator.batch_size)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T10:48:55.349634Z",
     "iopub.status.busy": "2024-09-19T10:48:55.349320Z",
     "iopub.status.idle": "2024-09-19T10:48:55.881589Z",
     "shell.execute_reply": "2024-09-19T10:48:55.880624Z",
     "shell.execute_reply.started": "2024-09-19T10:48:55.349601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5129652,
     "sourceId": 8577907,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
